{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from pandas_profiling import ProfileReport\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import yaml\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def load_params(param_path: str):\n",
    "    with open(param_path, \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_yaml = load_params(\"../params.yaml\")['amazon']\n",
    "\n",
    "df_test = pd.read_json(f\"{params_yaml['feature_extraction']['test_features_appended']}/TestFeaturesAppendedamazon.json\")\n",
    "df_train = pd.read_json(f\"{params_yaml['feature_extraction']['train_features_appended']}/TrainFeaturesAppendedamazon.json\")\n",
    "# Mamy zajmować się analizą dla treningu, więc operować będę na danych trenignowych\n",
    "X_train = df_train.drop(columns='overall')\n",
    "y_train = df_train['overall']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie rozkładu klas w zbiorze\n",
    "\n",
    "Jak widać klasy nie są równoliczne, co może powodować późniejsze problemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.groupby(\"overall\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Powyższa tabela przedstawia dane numeryczne. Można dojść do wniosku, że recenzje na stronie są raczej dobre - ich średnia to 4.2. Długość recenzji różni się - można podejrzewać, że te oceniane najbardziej skrajnie posiadają najdłuższe recenzje. Atrybut freshness informuje nas o tym ile dni minęło między recenzją, a datą a najnowszej recenzji.\n",
    "\n",
    "### Sprawdzenie rodzaju danych dla cech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nazwy kolumn: {df_train.columns.values}\")\n",
    "print(f\"Liczba danych kategorycznych: {np.sum(X_train.dtypes == 'object')}\")\n",
    "print(f\"Liczba danych numerycznych: {np.sum(X_train.dtypes == 'int64') + np.sum(X_train.dtypes == 'float64')}\")\n",
    "print(f\"Liczba danych typu bool: {np.sum(X_train.dtypes == 'bool')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie rodzaju zmiennej wyjściowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rodzaj zmiennej wyjściowej: {y_train.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wizualizacja za pomocą t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = X_train.select_dtypes(include='number')\n",
    "x = x.fillna(x.median())\n",
    "standarized_data = StandardScaler().fit_transform(x)\n",
    "tsne = TSNE(n_components=2, perplexity=50, learning_rate=200)\n",
    "tsne_df = pd.DataFrame(data=tsne.fit_transform(standarized_data), columns=['principal_1', \"principal_2\"])\n",
    "tsne_df = pd.concat([tsne_df, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(figsize=(15, 10))\n",
    "sns.scatterplot(\n",
    "    x=\"principal_1\",\n",
    "    y=\"principal_2\",\n",
    "    hue=\"overall\",\n",
    "    palette='muted',\n",
    "    data=tsne_df\n",
    ").set_title(\"Wizualizacja z użyciem t-SNE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy i ile w zbiorze jest brakujących wartości? Dla jakich zmiennych? Co z tego wynika?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.isnull().values.any())\n",
    "print(f\"Number of null places {X_train.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_set = {}\n",
    "for col in X_train.columns:\n",
    "    null_set[col] = X_train[{col}].isnull().sum().to_numpy()[0]\n",
    "\n",
    "df = pd.DataFrame.from_dict(null_set, orient='index', columns=['null number'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.barplot(x=df.index, y='null number', data=df, palette='muted').set(title='Number of null values per column')\n",
    "plt.xticks(rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z powyższej analizy wynika, że jak już pojawiają się wartości typu NULL, to jest ich bardzo dużo. Najwięcej w kolumnach dotyczących stylu. Wynika to z tego, że konkretny rodzaj stylu był inny dla różnych produktów. Niesie to ze sobą ryzyko, że z tych kolumn nie będzie można wynieść za dużo informacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy któreś z cech są skorelowane? Co z tego może wynikać?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\").set(title='Macierz korelacji cech')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z powyższej macierzy korelacji wynika, że cecha freshness jest ujemnie skorelowana z unixReviewTime, co wynika z definicji tej cechy - mówi ona o czasie od najnowszej recenzji. Można się zasugerować, czy nie opłaca się zrezygnować z jednej z cech. Dość silnie skorelowana jest także freshness z verified - ich miara wynosi 0.5, co może oznaczać, że aby zweryfikować recenzje musi upłynąć trochę czasu i recenzje z niższym wskaźnikiem freshness nie zdążyły być jeszcze zakwalifikowane jako 'verified'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy któraś z cech koreluje ze zmienną wyjściową? Jeśli tak - która? Czy któraś nie koreluje?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_whole_set = df_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix_whole_set, annot=True, cmap=\"coolwarm\").set(title='Macierz korelacji pełnego datasetu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z powyższej analizy wynika, że cecha isBoughtForChristmas najsłabiej koreluje ze zmienną wyjściową - jej zmiana nie powoduje zmiany wyjścia. Podobnie słabo skorelowana jest reszta cech numerycznych."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czy zbiór danych wydaje się być wystarczająco informacyjny by rozwiązać zadanie analizy sentymentu?\n",
    "\n",
    "\n",
    "Do tej pory przeanalizowana została część numeryczna zbioru potrzebnego do analizy sentymentu. Z danych wynika, że najprawdopodobniej nie bylibyśmy w stanie poprawnie przeanalizować sentymentu mając do dyspozycji jedynie dane numerczyne, bez kategorycznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['reviewTime'] = pd.to_datetime(df_train['reviewTime'])\n",
    "reviews_by_month = df_train.groupby(pd.Grouper(key='reviewTime', freq='Y')).size()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "reviews_by_month.plot(kind='bar')\n",
    "plt.title('Number of Reviews by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Reviews')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać powyżej najwięcej recenzji było w 2016 roku, potem liczba zaczęła spadać, co może sugerować spadek zainteresowania produktami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df_train)\n",
    "profile.to_file(f\"{params_yaml['reports']['pandas_report']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przebadanie ile średnio jest tekstu w zależności od klasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_text_length_by_class = df_train.groupby(\"overall\")[\"reviewText\"].apply(lambda x: x.str.len().mean()).reset_index()\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.barplot(x=\"overall\", y='reviewText', data=average_text_length_by_class, palette='muted').set(title='Average review length per class')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.overall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane tekstowe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"tokenized_review\"] = df_train[\"reviewText\"].str.lower().str.split()\n",
    "df_exploded = df_train.explode(\"tokenized_review\").reset_index(drop=True).rename(columns={\"tokenized_review\": \"word\"})\n",
    "df_exploded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exploded = df_exploded[~df_exploded[\"word\"].isin(stop)]\n",
    "print(df_exploded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 20))\n",
    "sns.countplot(\n",
    "    y=\"word\",\n",
    "    data=df_exploded,\n",
    "    order=df_exploded[\"word\"].value_counts().iloc[:20].index,\n",
    "    hue=\"overall\",\n",
    ")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_exploded[df_exploded[\"word\"].isin([\"use\", \"used\", \"one\", \"like\", \"software\"])]\n",
    "\n",
    "print(df_filtered[\"word\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać, mimo krótszych wypowiedzi podczas dobrej oceny słowa use, vent, dryer, great są bardzo popularne w gdy produkt oceniany był na 5. Całkowicie zbiór wydaje się dominować słowo dryer, use/used - co sugeruje, że opisy dotyczą faktycznie korzystania z produktów i są konstruktywnymi opiniami. Należy jednak zwrócić uwagę Na liczność klas. Ocen bardzo dobrych jest dużo więcej niż tych na 2. Dominują słowa use i used. Które wpływają w znacznym stopniu na sentyment.\n",
    "\n",
    "\n",
    "Można także zauważyć, że mimo mniejszej liczności słów w tekście ocen dobrych najpopularniejsze słowa zostały zdominowane przez tę klasę, co sugeruje, że oceniający wykorzystują podobny zasób słownictwa, gdy wypowiadają się dobrze o produkcie. Widać także, że oceny 4 zajmują drugie miejsce pod względem liczności najpopularniejszych słów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja długości"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "# na wykładzie dotychczas nie było nic o normalizacji i równoważeniu klas.\n",
    "# jedyne co znalazłem to TfidfVectorizer - nie umiałem wykorzystać tego, bo nie do końca rozumiem jak przedstawić zrównoważenie na wykresie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove special characters and numbers\n",
    "df_train[\"clean_text\"] = df_train[\"reviewText\"].str.lower().str.replace(r'[^a-zA-Z\\s]', '')\n",
    "\n",
    "df_train[\"original_and_clean_diff\"] = df_train['reviewLength'] - df_train[\"clean_text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza ile znaków było przed usunięciem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"reviewLength\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza ile znaków usunięto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"original_and_clean_diff\"].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać tekst można ocenić dobrze. Średnio na recenzję usuwano 27 znaków. Odejmując to od średnio 744 nie jest to zły znak. Można więc ocenić, że średnia długość 744 świadczy o tym, że recenzje są stosunkowo długie i czyste. Niepokojące jest odchylenie standardowe, które w obu przypadkach jest bardzo duże. Świadczy to o tym, że niektóre recenzje mogą składać się jedynie ze znaków specjalnych, bądź liczb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
